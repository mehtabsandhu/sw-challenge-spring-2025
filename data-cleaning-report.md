# The 4 data errors, how I detected these anomalies, and how I addressed them:

**Duplicate Timestamps:** Certain records had the same timestamp, yet different prices and sizes. To comfirm duplicate timestamps, I looped through all records backwards, and compared each record's timestamp to its preceding record's timestamp. If they were the same, I removed the record with the lower size (volume), as the record with the larger size (despite the price) is more representative of stock movement at that moment of time.
**Negative Prices** Certain records had a negative price entry, which isn't possible. This was likely just a sign error. To correct these negative records, I checked if each price was negative in the data cleaning stage, and adjusted it to positive if so. Rather than tossing these records out, I kept them because the positive prices were extremely similar to the prices of records around them.
**Outlier Prices** Certain records had prices that were massive outliers compared to the data around them. For example, a price of 41.678 prior to the average price of around 416.80. This was likely due to a misplaced decimal. To correct for this, I checked if each price was below 300 (well below the established average price of about $415). If so, I multiplied these outlier datapoints by 10, so that they were similar to the prices around them.
**Missing Records** Certain records had missing prices. I checked this during the data loading process, by seeing if "" (indicating an empty field) was present in either the timestamp, price, or size fields of a record. If so, I simply skipped over the record